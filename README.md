# MiniGPT
MiniGPT is a character-level GPT-style language model built using PyTorch. It uses embeddings, positional encoding, and a transformer architecture to learn text patterns and generate responses autoregressively. This project is designed for educational purposes to understand how transformer-based language models work at a low level.
